{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Cropping2D, Lambda, Input, BatchNormalization, Concatenate, concatenate\n",
    "from keras.layers.core import Activation, Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples_list(sampledir, exclude=[], d_range=[]):\n",
    "    samples = []\n",
    "    labelcount = []\n",
    "    for fname in os.listdir(sampledir):\n",
    "        if fname[-4:]=='.png' and not fname[0] in exclude:\n",
    "            d = int(fname.split('__')[-1].split('_')[0])\n",
    "            if len(d_range) > 0 and (d < d_range[0] or d > d_range[1]):\n",
    "                continue\n",
    "            label = int(fname[0])\n",
    "            samples.append((os.path.join(sampledir, fname), label))\n",
    "            while len(labelcount) < label+1:\n",
    "                labelcount += [0]\n",
    "            labelcount[label] += 1\n",
    "    print('label counts:')\n",
    "    for i in range(len(labelcount)):\n",
    "        print('{}: {}'.format(i, labelcount[i]))\n",
    "    print('total: {}'.format(len(samples)))\n",
    "    return samples\n",
    "\n",
    "def augment_samples_list(samples, mult=[1, 1, 1], tx=[0, 1], ty=[0, 1]):\n",
    "    augs = []\n",
    "    for sample in samples:\n",
    "        x = mult[sample[1]]-1\n",
    "        for i in range(x):\n",
    "            shiftx = np.random.randint(tx[0], tx[1]+1)\n",
    "            shifty = np.random.randint(ty[0], ty[1]+1)\n",
    "            sample_aug = [sample[0], sample[1], shiftx, shifty]\n",
    "            augs.append(sample_aug)\n",
    "    return samples + augs\n",
    "\n",
    "def filter_samples_by_distance(samples, drange=[0, 100]):\n",
    "    filtered_samples = []\n",
    "    for sample in samples:\n",
    "        fname = sample[0].split('/')[-1]\n",
    "        dee = int(fname.split('_')[2])\n",
    "        if drange[0] < dee < drange[1]:\n",
    "            filtered_samples.append(sample)\n",
    "    return filtered_samples\n",
    "\n",
    "def datagen(samples, batch_size=32, n_class=4, grey=False):\n",
    "    n_samples = len(samples)\n",
    "    while True:\n",
    "        samples = shuffle(samples)\n",
    "        for offset in range(0, n_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            \n",
    "            images = []\n",
    "            labels = []\n",
    "            for batch_sample in batch_samples:\n",
    "                im = mpim.imread(batch_sample[0])\n",
    "                if grey:\n",
    "                    im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "#                     im = cv2.cvtColor(im, cv2.COLOR_RGB2LAB)\n",
    "#                     im = im[:, :, 2]\n",
    "                if len(batch_sample) > 2:\n",
    "                    tx = batch_sample[2]\n",
    "                    ty = batch_sample[3]\n",
    "                    nrow, ncol = im.shape[:2]\n",
    "                    T = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "                    im = cv2.warpAffine(im, T, (ncol, nrow))\n",
    "                images.append(im)\n",
    "                labels.append(batch_sample[1])\n",
    "                \n",
    "            images = np.array(images)\n",
    "            if grey:\n",
    "                newshape = [x for x in images.shape] + [1]\n",
    "                images = np.reshape(images, newshape)\n",
    "            labels = keras.utils.to_categorical(np.array(labels), num_classes=n_class)\n",
    "            \n",
    "            yield shuffle(images, labels)\n",
    "            \n",
    "def count_sample_distro(samples):\n",
    "    label_counts = []\n",
    "    for sample in samples:\n",
    "        label = sample[1]\n",
    "        while len(label_counts) < label+1:\n",
    "            label_counts += [0]\n",
    "        label_counts[label] += 1\n",
    "        \n",
    "    total_count = sum(label_counts)\n",
    "    max_count = max(label_counts)\n",
    "    print('label counts, proportion, mult')\n",
    "    for i, label in enumerate(label_counts):\n",
    "        print('{} {:5.3f} {:6.2f}'.format(label, 1.0*label/total_count, 1.0*max_count/label))\n",
    "    print('total', total_count)\n",
    "    return label_counts\n",
    "\n",
    "def get_samples_list_recursive(sample_root, exclude=[]):\n",
    "    fnames = os.listdir(sample_root)\n",
    "    samples = []\n",
    "    for fname in fnames:\n",
    "        if not (fname[0] in exclude) and fname[-4:] == '.png':\n",
    "            samples.append([os.path.join(sample_root, fname), int(fname[0])])\n",
    "        elif os.path.isdir(os.path.join(sample_root, fname)):\n",
    "            new_root = os.path.join(sample_root, fname)\n",
    "            add_samples = get_samples_list_recursive(new_root, exclude)\n",
    "            samples += add_samples\n",
    "    return samples            \n",
    "\n",
    "def test_exhaustive(samples, model='model.h5', batch_size=32, grey=False):\n",
    "    model = load_model(model)\n",
    "    confusion = np.zeros((3, 3))\n",
    "    \n",
    "    N_bat = len(samples)//batch_size + 1\n",
    "    for offset in range(0, len(samples), batch_size):\n",
    "        batch_number = offset//batch_size+1\n",
    "        if batch_number % 10 == 0:\n",
    "            print('batch', batch_number, 'of', N_bat)\n",
    "        labels = []\n",
    "        imgs = []\n",
    "        for sample in samples[offset:offset+batch_size]:\n",
    "            img = mpim.imread(sample[0])\n",
    "            if grey:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "#                 img = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "            labels.append(sample[1])\n",
    "\n",
    "            if len(sample) > 2:\n",
    "                tx = sample[2]\n",
    "                ty = sample[3]\n",
    "                T = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "                nrow, ncol = img.shape[:2]\n",
    "                img = cv2.warpAffine(img, T, (ncol, nrow))\n",
    "\n",
    "            imgs.append(img)\n",
    "        imgs = np.array(imgs)\n",
    "        if grey:\n",
    "            newshape = [x for x in imgs.shape] + [1]\n",
    "            imgs = np.reshape(imgs, newshape)\n",
    "        preds = model.predict(imgs)\n",
    "        pred_labels = [int(np.argmax(pred)) for pred in preds]\n",
    "\n",
    "        for label, pred_label in zip(labels, pred_labels):\n",
    "            confusion[label][pred_label] += 1\n",
    "\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample generation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = get_samples_list_recursive('samples', exclude=['3'])\n",
    "# samples = augment_samples_list(samples, mult=[1, 22, 4], tx=[-50, 51])\n",
    "_ = count_sample_distro(samples)\n",
    "\n",
    "samples = filter_samples_by_distance(samples, [0, 10])\n",
    "samples = augment_samples_list(samples, mult=[1, 18, 2], tx=[-50, 50], ty=[0, 1])\n",
    "_ = count_sample_distro(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplegen = datagen(samples, batch_size=10, n_class=3, grey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(samplegen)\n",
    "\n",
    "grey = False\n",
    "cropx = 50\n",
    "cropy = 0\n",
    "\n",
    "print(imgs[0].shape)\n",
    "\n",
    "if imgs[0].shape[-1] < 3:\n",
    "    grey = True\n",
    "ncols = 5\n",
    "for i, img in enumerate(imgs):\n",
    "    if i % ncols == 0:\n",
    "        plt.figure(figsize=(12, 12))\n",
    "    plt.subplot(1, ncols, (i%ncols)+1)\n",
    "    img = img[cropy:-cropy-1, cropx:-cropx-1]\n",
    "    if grey:\n",
    "        plt.imshow(np.squeeze(img), cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "#     plt.gca().set_xlim([0+50, 800-50])\n",
    "#     plt.gca().set_ylim([0+100, 600-100])\n",
    "    plt.gca().set_title(labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Net definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_multiscale():\n",
    "    input_tensor = Input(shape=(None, None, 3), name=\"input_tensor\") # three channels, any size\n",
    "    \n",
    "    # monoscale layers\n",
    "    conv_com1 = Conv2D(16, (3, 3), activation='relu')(input_tensor)\n",
    "    batnorm1 = BatchNormalization()(conv_com1)\n",
    "    maxpool1 = MaxPooling2D()(batnorm1)\n",
    "    conv_com2 = Conv2D(32, (3, 3), activation='relu')(maxpool1)\n",
    "    batnorm2 = BatchNormalization()(conv_com2)\n",
    "    conv_com3 = Conv2D(64, (3, 3), activation='relu')(batnorm2)\n",
    "    batnorm3 = BatchNormalization()(conv_com3)\n",
    "    conv_com4 = Conv2D(128, (3, 3), activation='relu')(batnorm3)\n",
    "    batnorm4 = BatchNormalization()(conv_com4)\n",
    "    maxpool2 = MaxPooling2D()(batnorm4)\n",
    "    dropout1 = Dropout(0.2)(maxpool2)\n",
    "    \n",
    "    # multiscale layers\n",
    "    conv_sc3_1 = Conv2D(128, (3, 3), activation='relu')(dropout1)\n",
    "    conv_sc3_2 = Conv2D(256, (3, 3), activation='relu')(conv_sc3_1)\n",
    "    gap_sc3 = GlobalAveragePooling2D()(conv_sc3_2)\n",
    "    \n",
    "    conv_sc5_1 = Conv2D(128, (5, 5), activation='relu')(dropout1)\n",
    "    conv_sc5_2 = Conv2D(256, (5, 5), activation='relu')(conv_sc5_1)\n",
    "    gap_sc5 = GlobalAveragePooling2D()(conv_sc5_2)\n",
    "    \n",
    "    conv_sc7_1 = Conv2D(128, (7, 7), activation='relu')(dropout1)\n",
    "    conv_sc7_2 = Conv2D(256, (7, 7), activation='relu')(conv_sc7_1)\n",
    "    gap_sc7 = GlobalAveragePooling2D()(conv_sc7_2)\n",
    "    \n",
    "    concat = concatenate([gap_sc3, gap_sc5, gap_sc7])\n",
    "    \n",
    "    # dense layers\n",
    "    dense1 = Dense(512, activation='relu')(concat)\n",
    "    dropout2 = Dropout(0.2)(dense1)\n",
    "    dense2 = Dense(256, activation='relu')(dense1)\n",
    "    logit = Dense(3, activation='softmax')(dense2)\n",
    "    \n",
    "    model = Model(inputs=input_tensor, outputs=logit)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netms = net_multiscale()\n",
    "netms.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_nvidia(n_class=4):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Cropping2D(((0, 0), (250, 250)), input_shape=(600, 800, 3)))\n",
    "    \n",
    "    model.add(Conv2D(24, kernel_size=(5, 5), strides=(2, 2)))\n",
    "    model.add(Activation('relu')) # the paper doesn't mention activation function, but isn't that needed?\n",
    "    \n",
    "    model.add(Conv2D(36, kernel_size=(5, 5), strides=(2, 2)))\n",
    "    model.add(Activation('relu')) \n",
    "    \n",
    "    model.add(Conv2D(48, kernel_size=(5, 5), strides=(2, 2)))\n",
    "    model.add(Activation('relu')) \n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1)))\n",
    "    model.add(Activation('relu')) \n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), strides=(1, 1)))\n",
    "    model.add(Dropout(0.30))\n",
    "    model.add(Activation('relu')) \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(n_class))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=Adam(lr=1e-6), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_simple(n_class=4):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Cropping2D((100, 250), input_shape=(600, 800, 3)))\n",
    "    \n",
    "    model.add(Conv2D(8, kernel_size=(5, 5)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(16, kernel_size=(5, 5)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(5, 5)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(n_class))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=1e-6), loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net2(n_class=3):\n",
    "    model = Sequential()\n",
    "    model.add(Cropping2D((100, 250), input_shape=(600, 800, 3)))\n",
    "    \n",
    "    model.add(Conv2D(16, kernel_size=(5, 5)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(5, 5)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size=(5, 5)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(n_class))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netgrey(n_class=3):\n",
    "    model = Sequential()\n",
    "    model.add(Cropping2D((100, 50), input_shape=(600, 800, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) # scale by half\n",
    "    model.add(Lambda(lambda x: 2.0*x-1.0))\n",
    "    \n",
    "    model.add(Conv2D(8, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(16, kernel_size=(5, 5)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "#     model.add(Dense(256))\n",
    "#     model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(n_class))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netgrey2(n_class=3):\n",
    "    model = Sequential()\n",
    "    model.add(Cropping2D((0, 50), input_shape=(600, 800, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) # scale by half\n",
    "    model.add(Lambda(lambda x: 2.0*x-1.0))\n",
    "    \n",
    "    model.add(Conv2D(8, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(16, kernel_size=(5, 5)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "#     model.add(Dense(256))\n",
    "#     model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(n_class))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netungrey(n_class=3):\n",
    "    model = Sequential()\n",
    "    model.add(Cropping2D((0, 50), input_shape=(600, 800, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) # scale by half\n",
    "    model.add(Lambda(lambda x: 2.0*x-1.0))\n",
    "    \n",
    "    model.add(Conv2D(8, kernel_size=(3, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(16, kernel_size=(5, 5)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "#     model.add(Dense(256))\n",
    "#     model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(n_class))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, samples, batch_size=32, epochs=1, grey=False):        \n",
    "    train_samples, valid_samples = train_test_split(samples, test_size=0.25)\n",
    "    train_gen = datagen(train_samples, batch_size=batch_size, n_class=3, grey=grey)\n",
    "    valid_gen = datagen(valid_samples, batch_size=batch_size, n_class=3, grey=grey)\n",
    "    \n",
    "    train_step = math.ceil(len(train_samples)/batch_size)\n",
    "    valid_step = math.ceil(len(valid_samples)/batch_size)\n",
    "    \n",
    "    history = model.fit_generator(train_gen, steps_per_epoch=train_step,\n",
    "                                  validation_data=valid_gen, validation_steps=valid_step,\n",
    "                                  epochs=epochs, verbose=1)\n",
    "    model.save('model.h5')\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = get_samples_list_recursive('samples', exclude=['3'])\n",
    "samples = augment_samples_list(samples, mult=[1, 21, 3], tx=[-50, 50], ty=[0, 1])\n",
    "_ = count_sample_distro(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = net_multiscale()\n",
    "h = train(model, samples, batch_size=32, epochs=1, grey=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = get_samples_list_recursive('samples', exclude=['3'])\n",
    "samples = augment_samples_list(samples, mult=[1, 21, 3], tx=[-50, 50], ty=[0, 1])\n",
    "_ = count_sample_distro(samples)\n",
    "model = load_model('model.h5')\n",
    "# model.summary()\n",
    "h = train(model, samples, batch_size=32, epochs=4, grey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further training on only close-range data\n",
    "samples = get_samples_list_recursive('samples', exclude=['3'])\n",
    "samples = augment_samples_list(samples, mult=[1, 21, 3], tx=[-50, 50], ty=[0, 1])\n",
    "xsamples = filter_samples_by_distance(samples, drange=[0, 15])\n",
    "_ = count_sample_distro(xsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.h5')\n",
    "h = train(model, xsamples, batch_size=32, epochs=4, grey=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = get_samples_list_recursive('samples', exclude=['3'])\n",
    "samples = augment_samples_list(samples, mult=[1, 10, 2], tx=[-50, 51])\n",
    "_ = count_sample_distro(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conf = test_exhaustive(samples, model='model.h5', batch_size=64, grey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(conf, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conf)\n",
    "accuracy = sum([conf[i, i] for i in range(len(conf))])/sum(sum(conf))\n",
    "print('accuracy', accuracy)\n",
    "\n",
    "for i in range(len(conf)):\n",
    "    print('class', i)\n",
    "    precision = conf[i, i] / (sum(conf[:, i])) # true +ve / (true +ve + false +ve)\n",
    "    recall = conf[i, i] / (sum(conf[i, :])) # true +ve / (true+ve + false -ve)\n",
    "    print('precision', precision)\n",
    "    print('recall', recall)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = get_samples_list('samples', exclude=['3'])\n",
    "samples = augment_samples_list(samples, mult=[1, 150, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_gen = datagen(samples, batch_size=32, n_class=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_simple92.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(samples_gen)\n",
    "preds = model.predict(imgs, len(imgs), verbose=0)\n",
    "# print(preds.shape)\n",
    "# for pred, label in zip(preds, labels):\n",
    "#     print(np.argmax(label), np.argmax(pred), pred)\n",
    "\n",
    "good = 0\n",
    "for label, pred in zip(labels, preds):\n",
    "    if np.argmax(label) == np.argmax(pred):\n",
    "        good += 1\n",
    "print('accuracy', good/len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imx = mpim.imread('samples/0__21_1579319374_884872913.png')\n",
    "imx = np.expand_dims(imx, axis=0)\n",
    "print(imx.shape)\n",
    "p = model.predict(imx)\n",
    "print(np.argmax(p[0]), p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(imgs), 3):\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for j in range(3):\n",
    "        if i + j < len(imgs):\n",
    "            plt.subplot(1, 3, j+1)\n",
    "            plt.imshow(imgs[i+j])\n",
    "            real_class = np.argmax(labels[i+j])\n",
    "            detect_class = np.argmax(preds[i+j])\n",
    "            confidence = np.max(preds[i+j])\n",
    "            plt.gca().set_title('rel {} det {} con {:5.3f}'\\\n",
    "                                .format(real_class, detect_class, confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
